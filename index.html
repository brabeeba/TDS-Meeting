<!DOCTYPE html>
<html lang="en">
	<head>
    	<meta charset="utf-8">
    	<title>TDS Meeting</title>
    	<meta name="viewport" content="width=device-width, initial-scale=1.0">
    	<meta name="description" content="">
    	<meta name="author" content="">

    	<!-- Le styles -->
    	<link href="../personal_site/css/bootstrapFlatly.min.css" rel="stylesheet">
    	<style>
      	body {
        	/*padding-top: 60px;  60px to make the container go all the way to the bottom of the topbar */
      	}
    	</style>
    	<link href="../personal_site/css/bootstrap-responsive.min.css" rel="stylesheet">
    	<link href="../personal_site/css/main.css" rel="stylesheet">
	</head>
	<body>
	<div class="container">
	<div class="row-fluid">
	  <h3>TDS Meeting</h3>
   </div>
	<div class="row-fluid voffset1">
      	<span class="icon-time"></span><strong>Time:</strong> Fridays 12am-1:30pm, Fall Semester 2020 (first Meeting 9/4)
	</div>
	 <div class="row-fluid voffset1">
	  <span class="icon-map-marker"></span><strong>Location:</strong> Over Zoom <br>
	  
	</div>
	 <div class="row-fluid voffset1">
	  <span class="icon-envelope"></span><strong>Organizers:</strong> Nancy Lynch (lynch at csail dot mit dot edu)<br>
	</div>
<div class="row-fluid voffset1">
	<div class="col-md-10 colp-lg-8" >
   		<img src="./triple.png" class="img-rounded img-responsive" alt="my photo">
</div>
  <div class="row voffset1">
    <div class="col-md-12">
      <section id="publications">
      	

        <h3>(Tentative) Schedule</h3>
		
		<p>(9/4) Informal meeting of TDS group members.:  Nancy Lynch</p>
			<ul>
		<li>Every presents what they are working on.</li>
		<li>Explain the format of the TDS meeting</li>
		</ul>
		
		<p>(9/11) Spiking Neural Networks Through the Lens of Streaming Algorithms:  Yael Hitron</p>
			<ul>
			<strong>Abstract:</strong>
			<p>We initiate the study of biological neural networks from the perspective of streaming algorithms.  Like computers, human brains suffer from memory limitations which pose a significant obstacle when processing large scale and dynamically changing data. In computer science, these challenges are captured by the well-known streaming model, which can be traced back to Munro and Paterson ‘78 and has had significant impact in theory and beyond. In the classical streaming setting, one must compute some function f of a stream of updates S={u1,...,um}, given restricted single-pass access to the stream. The primary complexity measure is the space used by the algorithm.</p> 

			<p>In contrast to the large body of work on streaming algorithms, relatively little is known about the computational aspects of data processing in biological neural networks. In this work, we seek to connect these two models, leveraging techniques developed in for streaming algorithms to better understand neural computation. In particular, we consider the spiking neural network model, a distributed model of biological networks in which nodes (neurons) are connected by edges (synapses), and communicate with their neighbors via spiking (i.e., firing). Our primary goal is to design networks for various computational tasks using as few auxiliary (non-input or output) neurons as possible. The number of auxiliary neurons can be thought of as the ‘space’ required by the network.</p>

		<p>Previous algorithmic work in spiking neural networks has many similarities with streaming algorithms. However, the connection between these two space-limited models has not been formally addressed. We take the first steps towards understanding this connection. On the upper bound side, we design neural algorithms based on known streaming algorithms for fundamental tasks, including distinct elements, approximate median, heavy hitters, and more. The number of neurons in our neural solutions almost matches the space bounds of the corresponding streaming algorithms. As a general algorithmic primitive, we show how to implement the important streaming technique of linear sketching efficiently in spiking neural networks. On the lower bound side, we give a generic reduction, showing that any space-efficient spiking neural network can be simulated by a space-efficient streaming algorithm. This reduction lets us translate streaming-space lower bounds into nearly-matching neural-space lower bounds, establishing a close connection between these two models. </p>
		<strong>Slide:</strong>
		<li><a href="./streaming_neural.pdf">Slide</a></li>
		</ul>

		<p>(9/18) Striosomes Selectively Mediate Value-Based Learning Possibly Through Fast Spiking Inhibitory Interneurons: Sabrina Drammis, Jiajia</p>
			<ul>
			<strong>Abstract:</strong>
			<p>Learning valence-based responses to favorable and unfavorable options requires judgments of the relative value of the options and is necessary for species survival. We have found, using engineered mice, that circuit connectivity and function of the striosome compartment of the striatum are critical for this type of learning. Calcium imaging during valence-based learning exhibited a selective correlation between learning and striosomal, but not matrix, signals. This striosomal activity encoded discrimnitation learning and correlated with task engagement. Striosomal function during discrimination learning was distributed in aging, and severely so in a mouse model of Huntington's disease. Anatomical and functional connectivity of parvalbumin-positive, putative fast-spiking interneurons (FSIs) to striatal projection neurons was enhanced in striosomes compared to matrix in mice that learned. Based on our computation model, we suggest that FSIs can modulated striosomal signal-to-noise ratio, crucial for discrimination and learning.</p> 
			<strong>Slide:</strong>
		<li><a href="./striatum.pdf">Slide</a></li>
		</ul>

		<p>(10/2) A Comprehensive and Predictive Agent-based Model for Collective House-Hunting in Ant Colonies: Jiajia</p>
			<ul>
			<strong>Abstract:</strong>
			<p>The decentralized cognition of animal groups is both a challenging biological problem and a potential basis for bio-inspired design. The understanding of these systems and their application can benefit from modeling and analysis of the underlying algorithms. In this study, we define a modeling framework that can be used to formally represent all components of such algorithms. As an example application of the framework, we adapt to it the much-studied house-hunting algorithm used by emigrating colonies of *Temnothorax* ants to reach consensus on a new nest. We provide a Python simulator that encodes accurate individual behavior rules and produces simulated behaviors consistent with empirical observations, on both the individual and group levels. Our model successfully reproduces experimental results showing the high cognitive capacity of colonies, their rational time investment during decision-making, and their ability to avoid and repair splits with the help of social information. We also use the model to make predictions about several unstudied aspects of emigration behavior. The results suggest the value of individual sensitivity to site population for ensuring consensus, and they indicate a more complex relationship between individual behavior and the speed/accuracy trade-off than previously appreciated. The model proved relatively weak at resolving colony divisions among multiple sites, suggesting either limits to the ants' ability to reach consensus, or an aspect of their behavior not captured in our model. It is our hope that these insights and predictions can inspire further research from both the biology and computer science community.</p> 
			<strong>Slide:</strong>
		<li><a href="https://docs.google.com/presentation/d/1GaP9RxY0jdB0vP8hYFIz6k93B3W5bHYulpW71gbUTd8/edit#slide=id.p">Slide</a></li>
		<strong>Paper:</strong>
		<li><a href="https://www.biorxiv.org/content/10.1101/2020.10.07.328047v1">Paper</a></li>
			
		</ul>

		<p>(10/16) How to Color a French Flag: Biologically Inspired Algorithms for Scale-Invariant Patterning: Bertie Ancona</p>
			<ul>
			<strong>Abstract:</strong>
			<p> In the French flag problem, initially uncolored cells on a grid must differentiate to become blue, white or red. The goal is for the cells to color the grid as a French flag, i.e., a three-colored triband, in a distributed manner. To solve a generalized version of the problem in a distributed computational setting, we consider two models: a biologically-inspired version that relies on morphogens (diffusing proteins acting as chemical signals) and a more abstract version based on reliable message passing between cellular agents.</p>
			<p> Much of developmental biology research has focused on concentration-based approaches using morphogens, since morphogen gradients are thought to be an underlying mechanism in tissue patterning. We show that both our model types easily achieve a French ribbon - a French flag in the 1D case. However, extending the ribbon to the 2D flag in the concentration model is somewhat difficult unless each agent has additional positional information. Assuming that cells are identical, it is impossible to achieve a French flag or even a close approximation. In contrast, using a message-based approach in the 2D case only requires assuming that agents can be represented as constant-size state machines.</p> 
			
		</ul>

		<p>(11/13) Network Decomposition and Distributed Derandomization: Mohsen Ghaffari</p>
			<ul>
			<strong>Abstract:</strong>
			<p>  I will provide an overview of a recent line of work [RozhoÅˆ
and Ghaffari at STOC 2020; Ghaffari, Harris, and Kuhn at FOCS 2018;
and Ghaffari, Kuhn, and Maus at STOC 2017], which presented the first
efficient deterministic network decomposition algorithm as well as a
general derandomization result for distributed graph algorithms.
Informally, the derandomization result shows that any
(locally-checkable) graph problem that admits an efficient randomized
distributed algorithm also admits an efficient deterministic
distributed algorithm. These results resolve several central and
decades-old open problems in distributed graph algorithms.</p> 
			<strong>Reading List:</strong>
			<li><a href="https://arxiv.org/abs/1907.10937">Vaclav Rozhon and Mohsen Ghaffari. Polylogarithmic-Time Deterministic Network Decomposition and Distributed Derandomization. ACM Symposium on Theory of Computing (STOC) 2020.</a> </li>
			<li><a href="https://arxiv.org/abs/1711.02194">Mohsen Ghaffari, David Harris, and Fabian Kuhn. On Derandomizing Local Distributed Algorithms. IEEE Symposium on Foundations of Computer Science (FOCS) 2018.</a> </li>
			<li><a href="https://arxiv.org/abs/1611.02663">Mohsen Ghaffari, Fabian Kuhn, and Yannic Maus. On the Complexity of Local Distributed Graph Problems. ACM Symposium on Theory of Computing (STOC) 2017.</a> </li>
			
		</ul>

			<p>(12/4) Locally Solvable Tasks and the Limitations of Valency Arguments: Hagit Attiya, Armando Castañeda, Sergio Rajsbaum</p>
			<ul>
			<strong>Abstract:</strong>
			<p>  An elegant strategy for proving impossibility results in distributed 
computing was introduced in the celebrated FLP consensus impossibility 
proof. This strategy is local in nature as at each stage, one 
configuration of a hypothetical protocol for consensus is considered, 
together with future valencies of possible extensions. This local 
nature makes the strategy very flexible, and has been used in numerous 
situations related to consensus. Hence, one would like to use it for 
impossibility results of two other well-known tasks: set agreement and 
renaming. This paper provides an  explanation of why impossibility 
proofs of these tasks have been of  a global nature. It shows that a 
protocol can always solve such tasks locally, in the following sense. 
Given a configuration and all its future valencies, if a single 
successor configuration is selected, then the protocol can reveal all 
decisions in this branch of executions, satisfying the task 
specification. This result is shown for both set agreement and 
renaming, implying that there are no local impossibility proofs for 
these tasks.</p> 
		</ul>

	</ul>
	<a href="https://accessibility.mit.edu/">Accessibility</a>
				
		
		
	<!--	<h4><strong>Unscheduled but need/want to fit in somewhere</strong></h4>
		<p>
			<ul>
				<li><a href="https://igi-web.tugraz.at/people/maass/psfiles/154.pdf">What Can a Neuron Learn with Spike-Timing-Dependent Plasticity?</a> Brabeeba might be interested in presenting.
			<li><a href="https://arxiv.org/abs/1803.09574">Long short-term memory and learning-to-learn in networks of spiking neurons</a>, Quanquan?</li>
			<li><a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004347">Decreasing-Rate Pruning Optimizes the Construction of Efficient and Robust Distributed Networks</a>, Navlakha, Barth, Bar-Joseph.</li>
			<li>Other learning papers people are interested in?</li>
			</ul>
		</p>-->
	  </section>
	</div>
</div>
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../personal_site/js/jquery-1.11.1.min.js"></script>
    <script src="../personal_site/js/bootstrap.min.js"></script>

</div>
</body>
</html>